	
	<!doctype html>
<html lang="en">
  <head>    
    <title>Gradient Descent - Why Sigmoid Neurons?</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

    
    <link href="../../css/milk.min.css" rel="stylesheet">
    <link href="../../css/milk-responsive.min.css" rel="stylesheet">     
    <link href="../../css/style.css" rel="stylesheet" type="text/css" media="all">
    <link href="../../css/highlight.css" rel="stylesheet" type="text/css" media="all">
    <link href="../../css/fonts.css" rel="stylesheet" type="text/css" media="all">
    <link rel="shortcut icon" href="../../images/gradient-ascent.ico">
    <link rel="apple-touch-icon" href="">
    <link rel="canonical" href="http://navinpai.github.io/ga/post/why-sigmoid-neurons/">
    <link rel="stylesheet" href="http://navinpai.github.io/gacss/monosocialiconsfont.css">

    
    <link href="../../rss.xml" type="application/atom+xml" rel="alternate" title="Gradient Ascent">    

  </head>
  <body>    
    <div class="navbar navbar-fixed-top">        
  <div id="navbar-inner">
          <div id="logo">
            <a href=""><img class= "logo" src="../../images/logo-3.png" width="100px"></img></a>
          </div>
  </div>
</div>


<div class="container">
  <div class="content">
    <div class="row-fluid">
      <div class="span12">
        <div class="posts">
      

	    
	  <div class="post">
	    <header class="post-header">
	        <h1><a href="../../post/why-sigmoid-neurons/">Why Sigmoid Neurons?</a></h1>
	        <div class="post-time">November 9 2016</div>
	    </header>
	    <div class="post-after">
	        <div class="tags">
	            
	                <a href="http://navinpai.github.io/ga/tags/book">book</a>              
	            
	        </div>
	    </div>
	    <hr>
	    <div class="post content">
	        <p>When I just started reading about Deep learning, a common thread I kept noticing was the usage of Sigmoid Neurons. It took quite a bit of intuition to figure this out. In fact, I even played around with a couple of different activation functions before slowly figuring out the simplistic beauty of the sigmoid. Today, I came aross the <a href="https://neuralnetworksanddeeplearning.com/chap1.html">Neural Networks and Deep Learning</a> online book, and it did an excellent job of explaining the same:</p>

<p>For learning purposes, we want one key characteristic of our function:</p>











  





  


<blockquote>
  <p>
We'd like the network to learn weights and biases so that the output from the network correctly classifies the digit. To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the network.
</p>
    <strong></strong>
    
      
    
</blockquote>

<p>And as we know, perceptrons don&rsquo;t work that way!</p>











  





  


<blockquote>
  <p>
The problem is that this isn't what happens when our network contains perceptrons. In fact, a small change in the weights or bias of any single perceptron in the network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1.
</p>
    <strong></strong>
    
      
    
</blockquote>

<p>And which is an almost perfect activation function for the use case we have?</p>











  





  


<blockquote>
  <p>
What about the algebraic form of What about the algebraic form of σ? How can we understand that? In fact, the exact form of σ isn't so important - what really matters is the shape of the function when plotted. Here's the shape:


<figure >
    
        <img src="../../images/sigmoid-function.png" />
    
    
    <figcaption>
        <h4>The Sigmoid Function</h4>
        
    </figcaption>
    
</figure>


If σ had in fact been a step function, then the sigmoid neuron would be a perceptron, since the output would be 1 or 0 depending on whether w⋅x+bw⋅x+b was positive or negative. [...] The smoothness σ means that small changes Δwj in the weights and Δb in the bias will produce a small change Δoutput in the output from the neuron.
</p>
    <strong></strong>
    
      
    
</blockquote>

<p>Such a beautiful function explained so eloquently. I&rsquo;d suggest reading <a href="https://neuralnetworksanddeeplearning.com/chap1.html">the book</a> for people just getting their feet wet in the field! It&rsquo;s an amazing resource!</p>

	    </div>
	    
	<div class="about">
	<p> 
     
    </p>
</div>
		<nav id="pagination">
			<a class="prev" href="http://navinpai.github.io/ga/post/tricking-neural-net/">Newer</a>
			<a class="next" href="http://navinpai.github.io/ga/post/deconv-layer-conv-layer/">Older</a>
		</nav>
	
		        <footer>
                    Built with <a href="https://github.com/spf13/hugo">Hugo</a> | Original theme: <a href="https://github.com/AlexFinn/simple-a">simple-a</a>
                    <p>&copy; Navin Pai 2016</p>
		        </footer>
		    </div>
		  </div>    
		</div>
      </div>
    </div>
    <script src="http://navinpai.github.io/gajs/highlight.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create',"UA-84823975-1", 'auto');
    ga('send', 'pageview');

</script>


</html>
