<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Paper on Gradient Ascent </title>
    <link>http://navinpai.github.io/ga/tags/paper/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2017-01-03 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>Deepmind Lab</title>
      <link>http://navinpai.github.io/ga/post/deepmind-lab/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>http://navinpai.github.io/ga/post/deepmind-lab/</guid>
      <description>&lt;p&gt;I think I begin practically every post on this blog talking about the pace with which Deep Learning has been progressing over the last few years. While this is really great for the domain as a whole, the lack of a standardised platform to test how good or bad an algorithm is has been lacking. The researchers over at DeepMind came up with &lt;strong&gt;Deepmind Lab&lt;/strong&gt; as a solution to the problem particularly in the field of First Person Shooter (FPS) gameplay. They published a paper titled &lt;a href=&#34;https://arxiv.org/abs/1612.03801v2&#34;&gt;Deep Mind Lab&lt;/a&gt; and also (&lt;em&gt;obviously&lt;/em&gt;) released the code for the same &lt;a href=&#34;https://github.com/deepmind/lab&#34;&gt;on Github&lt;/a&gt;.&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;Technically, the &amp;ldquo;Lab&amp;rdquo; is built on top of the Quake 3 Arena engine. (&lt;em&gt;#Nostalgia&lt;/em&gt;). Setting up a is a bit of a pain thanks to random bazel related errors, which seems to be a ritual for trying out anything new that comes out from Google/Alphabet (&lt;em&gt;but solutions were all easily google-able&lt;/em&gt;). But once the initial hiccups are done, everything works like a charm.&lt;/p&gt;

&lt;p&gt;You can play the levels as a human as well if you wish to (&lt;em&gt;which is the first thing I tried out&lt;/em&gt;), and I strongly recommend you do because you really get a feel of how useful a playground platform like this can be. You can do this using:&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
bazel run :game -- --level_script tests/demo_map
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;You also have a random agent ready to be trained. To play a level using the random agent, simply do:&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
bazel run :random_agent
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;For a couple of the initial levels, using tried and tested methods seems to work well enough with minimal training (&lt;em&gt;I ran my tests on my personal system, and didn&amp;rsquo;t really do any multi-day GPU learning bruhaha&lt;/em&gt;), and I&amp;rsquo;m pretty sure that people will all be going back to the iconic &lt;a href=&#34;https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf&#34;&gt;Playing Atari with Deep Reinforcement Learning&lt;/a&gt; paper (&lt;em&gt;and it&amp;rsquo;s variants&lt;/em&gt;) to find things to tinker around with.&lt;/p&gt;

&lt;p&gt;I didn&amp;rsquo;t really explore the lab as much as I would&amp;rsquo;ve liked to but definitely plan to do so in the near future. Releases like DeepMind Lab, and the &lt;a href=&#34;https://gym.openai.com&#34;&gt;OpenAI Gym&lt;/a&gt; are providing a much needed plug and play task based exploration areas for Reinforcement Learning, and it&amp;rsquo;s high time that others start doing similar stuff (&lt;em&gt;or at least using these as benchmarks and contributing back&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;PS Happy New Year! :)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1612.03801v2&#34;&gt;Deep Mind Lab&lt;/a&gt; by &lt;em&gt;Charles Beattie, Joel Z. Leibo, Denis Teplyashin, Tom Ward, Marcus Wainwright, Heinrich Küttler, Andrew Lefrancq, Simon Green, Víctor Valdés, Amir Sadik, Julian Schrittwieser, Keith Anderson, Sarah York, Max Cant, Adam Cain, Adrian Bolton, Stephen Gaffney, Helen King, Demis Hassabis, Shane Legg, Stig Petersen&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image to Image Translation</title>
      <link>http://navinpai.github.io/ga/post/image-to-image-translation/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>http://navinpai.github.io/ga/post/image-to-image-translation/</guid>
      <description>&lt;p&gt;&lt;em&gt;Generative Adversarial Networks&lt;/em&gt; really took the field by storm sometime last year when the iconic &lt;a href=&#34;https://arxiv.org/abs/1511.06434&#34;&gt;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks&lt;/a&gt; was published. Since then, every couple of weeks you&amp;rsquo;re sure to come across some application using the core DCGAN to create something astonishing. A couple of days back, researchers over at &lt;strong&gt;BAIR&lt;/strong&gt; came up with one such result.&lt;/p&gt;

&lt;p&gt;Their paper, titled &lt;a href=&#34;https://arxiv.org/abs/1611.07004&#34;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/a&gt;, applies the GAN model to translate between different representations of images. What I personally found interesting was that in their paper, they use a single network to do general-purpose translation. Just a couple years ago, even translating between 2 classes of representations required a crazy amount of model tuning, but GANs have truly risen up to the challenge.&lt;/p&gt;

&lt;p&gt;This paper really feels like it was written by an engineer at heart. Not only is there a &lt;a href=&#34;https://phillipi.github.io/pix2pix/&#34;&gt;Github repo&lt;/a&gt; with some really clean code, but the paper itself talks about many of the optimisations in the way an engineer, rather than a researcher, would. Let&amp;rsquo;s get to the interesting bits:&lt;/p&gt;

&lt;p&gt;Firstly, they create a U-Net architecture shape, with the basic understanding that the input and output share a lot of low level information.&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
To give the generator a means to circumvent the bottleneck for information like this, we add skip connections. Specifically, we add skip connections between each layer i and layer n − i, where n is the total number of layers. Each skip connection simply concatenates all channels at layer i with those at layer n − i.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;Next observation: Using just L2/L1 loss creates blurry images because they only capture low frequency correctness, and provide no incentive for high frequency correctness. So, they go on and create a method to allow the discriminator to understand high level correctness.&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
In order to model high-frequencies, it is sufficient to restrict our attention to the structure in local image patches. Therefore, we design a discriminator architecture – which we term a PatchGAN – that only penalizes structure at the scale of patches. This discriminator tries to classify if each N × N patch in an image is real or fake. We run this discriminator convolutationally across the image, averaging all responses to provide the ultimate output of D.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;They also use L1 loss in combination to ensure that the output isn&amp;rsquo;t dominated by the GAN, which tends to make images more colorful (&lt;em&gt;The Deep Dream filter&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s interesting to note that despite training on limited data, the accuracy they got was pretty sweet. Converting maps to aerial photos was trained using just 1096 images, but was able to fool mechanical turksa almost one in every five times, which is impressive, to say the least. I can already imagine use cases for such methods in the design industry, be it for designing clothes, or shoes, or even toys!&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;../../images/image-to-image.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Guess which column is generated by a DCGAN&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;Go read the paper, and check out the code as well (&lt;em&gt;I&amp;rsquo;ll probably do another post on the code, if I can get through it soon enough&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.07004&#34;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/a&gt; by &lt;em&gt;Phillip Isola, Jun-Yan Zhu, Tinghui Zhou and Alexei A. Efros&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tricking your Super-fancy Neural Net</title>
      <link>http://navinpai.github.io/ga/post/tricking-neural-net/</link>
      <pubDate>Wed, 23 Nov 2016 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>http://navinpai.github.io/ga/post/tricking-neural-net/</guid>
      <description>&lt;p&gt;While cleaning up my reading list earlier today, I came across this really cool paper from &lt;strong&gt;CVPR 2015&lt;/strong&gt; with the hard to ignore title: &lt;a href=&#34;https://arxiv.org/abs/1412.1897&#34;&gt;Deep Neural Networks are Easily Fooled&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I think anyone who has been working with Deep Learning systems (&lt;em&gt;or even Machine learning algorithms to a large extent&lt;/em&gt;) has come across multiple examples where you look at the result and wonder &amp;ldquo;&lt;em&gt;How on earth did I get that?&lt;/em&gt;&amp;rdquo;. I have fond memories of one of my projects at &lt;strong&gt;IIIT-B&lt;/strong&gt; which involved sketch classification, where my system was 99% confident that my sketch of an aeroplane was in fact a dog, leading one of my teammates to wonder if the dog was, in fact, inside the plane!&lt;/p&gt;

&lt;p&gt;The somewhat blackbox nature of Deep Learning systems only adds to the mystery, which is why I feel papers like this help provide some context to &amp;ldquo;how&amp;rdquo; we&amp;rsquo;re solving the problem at hand rather than the &amp;ldquo;what&amp;rdquo;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;../../images/tricked-sample.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Such Accurate, Much Wow!&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;For obvious reasons, the question to ask is how do you come up with these trick images?&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
The novel images we test DNNs on are produced by evolutionary algorithms (EAs). EAs are optimization algorithms inspired by Darwinian evolution. They contain a population of &#34;organisms&#34; (here, images) that alternately face selection (keeping the best) and then random perturbation (mutation and/or crossover). Which organisms are selected depends on the fitness function, which in these experiments is the highest prediction value a DNN makes for that image belonging to a class
[...]
Here, fitness is determined by showing the image to the DNN; if the image generates a higher prediction score for any class than has been seen before, the newly generated  individual becomes the champion in the archive for that class.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;They use different encodings to generate different types of incorrectly labelled images, including a direct encoding and an indirect encoding.&lt;/p&gt;

&lt;p&gt;Another method they use is also pretty cool. They use gradient ascent (&lt;em&gt;blog name FTW!&lt;/em&gt;) for this:&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
We calculate the gradient of the posterior probability for a specific class - here, a softmax output unit of the DNN - with respect to the input image using backprop, and then we follow the gradient to increase a chosen unitWe calculate the gradient of the posterior probability for a specific class - here, a softmax output unit of the DNN - with respect to the input image using backprop, and then we follow the gradient to increase a chosen unit’s activation.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;This technique was earlier described in &lt;a href=&#34;https://arxiv.org/abs/1312.6034&#34;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s interesting is also that these examples use one DNN for generation, but generalize across multiple DNNs, which seems to imply the features recognised are all very similar (&lt;em&gt;which is both good and bad imho&lt;/em&gt;). Absolutely beautiful discussion in the supplementary material as well, I thoroughly enjoyed reading this paper, and you should too!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1412.1897&#34;&gt;Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images&lt;/a&gt; by &lt;em&gt;Anh Nguyen, Jason Yosinski and Jeff Clune&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deconvolution Layer == Convolution Layer?</title>
      <link>http://navinpai.github.io/ga/post/deconv-layer-conv-layer/</link>
      <pubDate>Fri, 14 Oct 2016 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>http://navinpai.github.io/ga/post/deconv-layer-conv-layer/</guid>
      <description>&lt;p&gt;I stumbled across &lt;a href=&#34;https://arxiv.org/abs/1609.07009&#34;&gt;a note&lt;/a&gt; which expands an already brilliant paper: &lt;a href=&#34;https://arxiv.org/abs/1609.05158&#34;&gt;Realtime Image/Video Super Resolution using a Sub-Pixel CNN&lt;/a&gt; (&lt;em&gt;which I really should write about soon&lt;/em&gt;). The note basically tries to answer the question: Is the decovolution layer the same as a convolution layer in Low Resolution (LR) space?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR: Yes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Their reasoning was what really caught my eye. The crux of it is:&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
We notice that the different sets of weights in the kernel (1,1,4,4) are activated independently from each other.So we can easily break them into kernels as shown in the figure on the right.This operation is invertible (4,1,2,2) because each set of the weights are independent from each other during the convolution. In our paper,instead of convolving the kernel with the unpooleded sub-pixel image, we notice that the different sets of weights in the kernel (1,1,4,4) are activated independently from each other. So we can easily break them into kernels as shown in the figure on the right.This operation is invertible (4,1,2,2) because each set of the weights are independent from each other during the convolution.In our paper,instead of convolving the kernel with the unpooled sub­pixel image, we convolve (1,1,4,4) the kernel with the LR input directly as illustrated by the following figure.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;Another interesting part of the note was the realization that the representation power of a network in LR is mucn more than that in HR (&lt;em&gt;where you first upscale using, say, Bicubic and then pass this as input to the network&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Go on, read the note (&lt;em&gt;and the paper it expands&lt;/em&gt;) and the fascinating breakdown of the logic.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.07009&#34;&gt;Is the deconvolution layer the same as a convolutional layer?&lt;/a&gt;: &lt;em&gt;Wenzhe Shi, Jose Caballero, Lucas Theis, Ferenc Huszar, Andrew Aitken,Alykhan Tejani, Johannes Totz, Christian Ledig, Zehan Wang&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.05158&#34;&gt;Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network &lt;/a&gt;: &lt;em&gt;Wenzhe Shi, Jose Caballero, Lucas Theis, Ferenc Huszar, Andrew Aitken,Alykhan Tejani, Johannes Totz, Christian Ledig, Zehan Wang&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Batch Normalization in Neural Networks</title>
      <link>http://navinpai.github.io/ga/post/batch-normalization/</link>
      <pubDate>Fri, 07 Oct 2016 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>http://navinpai.github.io/ga/post/batch-normalization/</guid>
      <description>&lt;p&gt;Read a couple of interesting papers today from 2015 about using Batch Normalization in neural networks. Batch Normalization basically means that we normalize each activation individually. The reason for this, quoting the &lt;a href=&#34;https://arxiv.org/abs/1502.03167v3&#34;&gt;original paper&lt;/a&gt;&lt;/p&gt;











  





  


&lt;blockquote&gt;
  &lt;p&gt;
Training Deep Neural Networks is complicated by the fact that the distribution of each layer&#39;s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift.
&lt;/p&gt;
    &lt;strong&gt;&lt;/strong&gt;
    
      
    
&lt;/blockquote&gt;

&lt;p&gt;Their paper is a fascinting deep dive into the math of how layers are affected by the input, and how this covariate shift can be reduced by applying batch normalizations. Using batch normalization means we can use higher learning rates (since gradients do not explode or vanish), making the network more resilient. In fact, in their results they showed how they could use the batch normalized network to achieve the same accuracy as the vanilla network with half the training steps, and with higher learning rates upto 14x fewer steps!&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;../../images/batch-norm.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;The Batch Normalization Transform&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;This paper set up a bunch of other interesting papers which explored the same concept of batch normalization, and I&amp;rsquo;ll talk about two of them below.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://arxiv.org/abs/1510.01378&#34;&gt;first one&lt;/a&gt; notes that the original paper applies only to feed forward neural networks and attempts to explore batch normalization in Recurrent Neural Networks. They apply batch normalization on the input-to-hidden transition and oberved faster training and greater overfitting as well. The fact that the generalization performance didn&amp;rsquo;t seem to improve with batch normalization was opposite to what was seen for feedforward neural nets.&lt;/p&gt;

&lt;p&gt;However, a couple of months ago, &lt;a href=&#34;https://arxiv.org/abs/1603.09025v4&#34;&gt;another paper&lt;/a&gt; visited the same idea albeit in a slightly different manner &lt;em&gt;(in fact one of the authors is on both the papers)&lt;/em&gt;. Instead of applying the normalization on the input-to-hidden transition, they apply it horizontally between timesteps, using the consideration that RNNs are deepest in the time direction. Lo and behold, they now have the state of the art results (greater generalizability) with lesser convergence time.&lt;/p&gt;

&lt;p&gt;Truly an excellent set of papers exploring what seems, at first read, as a minor modification to an algorithm. Go on, read the papers!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1502.03167v3&#34;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt; &lt;em&gt;Sergey Ioffe, Christian Szegedy&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1510.01378&#34;&gt;Batch Normalized Recurrent Neural Networks&lt;/a&gt; &lt;em&gt;César Laurent, Gabriel Pereyra, Philémon Brakel, Ying Zhang, Yoshua Bengio&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1603.09025v4&#34;&gt;Recurrent Batch Normalization&lt;/a&gt; &lt;em&gt;Tim Cooijmans, Nicolas Ballas, César Laurent, Çağlar Gülçehre, Aaron Courville&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
